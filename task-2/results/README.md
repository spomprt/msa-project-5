# Сравнение технологий для генерации прайс-листов (CSV/XLS) из PostgreSQL

## Матрица сравнения

| Характеристика | SpringBatch | ApacheAirflow | K8s Job (CronJob) | Spark |
|---|---|---|---|---|
| Наличие конфигурации CRON-расписания | Есть через `@Scheduled`/Quartz; CRON поддерживается, но без отдельной оркестрации | Богатый планировщик, CRON/календарь, backfill | CronJob — нативная CRON-расписка (Job сам по себе без расписания) | Нет встроенного расписания, нужен Airflow/K8s/Crontab |
| Сложность реализации логики по обработке данных | Низкая–средняя: шаги/читатели/писатели из коробки, но есть обвязка | Низкая для простых DAG (операторы Bash/Python/SQL), логика чаще вне Airflow | Низкая: контейнер со скриптом/утилитой `psql \\COPY`/`COPY` | Высокая: API/кластер, трансформации; избыточно для вашей задачи |
| Ресурсоёмкость | Низкая–средняя (один pod/инстанс на джобу) | Средняя: webserver, scheduler, метаданные БД | Низкая: старт pod по расписанию и завершение | Высокая: драйвер + executors, даже при малом объёме |
| Масштабируемость под нагрузкой и сложность реализации | Средняя–высокая: параллелизм шагов, partitioning | Высокая для оркестрации множества задач/зависимостей | Средняя: горизонтально масштабируется на уровне k8s, логика в контейнере простая | Высокая по данным, но сложность и overhead велики |
| Сложность развёртывания в облаке и интеграция с микросервисами | Средняя: типичный Spring-микросервис | Высокая: отдельный кластер/сервис Airflow, CI/CD и секреты | Низкая: манифест CronJob + образ, вписывается в текущий кластер | Высокая: кластер/оператор Spark, сетевые/хранилищные настройки |
| Интеграция с логированием и мониторингом | Хорошая: Micrometer/Prometheus, структурные логи | Отличная: UI, логи, метрики, алерты из коробки | Простая: stdout в стек логов (ELK/Cloud Logging), метрики через sidecar/exporter | Средняя: Spark UI, интеграция с Prometheus/ELK требует настройки |

---

## Практические выводы и рекомендации

- **Самый простой и достаточный вариант сейчас:** **Kubernetes CronJob** с минимальным контейнером, который по расписанию выполняет SQL и пишет CSV (например, `psql -c "\COPY (SELECT ... JOIN ...) TO 'file.csv' CSV HEADER"`), затем кладёт файл в объектное хранилище (S3/GCS/Azure Blob).  
  - Плюсы: минимальная обвязка, дешёво по ресурсам, прекрасно встраивается в существующий кластер, легко мониторить через стандартные k8s-инструменты.

- **Если нужна «прикладная» батч-логика** (мультиклиентные шаблоны, ретраи/скипы по записям, аудит джоб, нотификации) — **Spring Batch** как отдельный микросервис отлично ляжет в вашу микросервисную архитектуру.

- **Если появятся цепочки задач/зависимости** (подготовка витрин, SLA, сдвиги окон, backfill и т. п.) — добавляйте **Apache Airflow** как оркестратор, который будет триггерить ваш CronJob или Spring Batch-сервис.

- **Spark** для текущего объёма **избыточен**: не окупит накладные расходы.

---

## Верхнеуровневый план по имплементации и конфигурации решения

- Контейнер: lightweight (alpine + `psql`/`pg_dump` + `awscli`/`gsutil`).  
- SQL: один `SELECT` с `JOIN` по `products`, `categories`, `clients`, `client_prices`; выгрузка через `COPY ... TO STDOUT WITH CSV HEADER`.  
- Хранение: выгружать в `s3://b2b-prices/{client}/{YYYY-MM-DD}/price.csv` (или аналог).  
- Секреты: `Secret`/`ExternalSecret` для creds БД и облака.  
- Мониторинг: `Completion`/`Failed` Events → Alertmanager, логи в ELK/Cloud Logging; метрики через `kube-state-metrics`/`prometheus-adapter`.  
